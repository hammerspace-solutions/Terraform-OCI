##############################################################################
# Oracle Cloud Infrastructure (OCI) Terraform Configuration - tfvars Example  #
##############################################################################

# --- Authentication and API ---
tenancy_ocid     = "ocid1.tenancy.oc1..xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" # Your tenancy OCID from OCI console
user_ocid        = "ocid1.user.oc1..xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"    # Your user OCID from OCI console
fingerprint      = "xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx"       # Fingerprint of your API key
private_key_path = "/home/user/.oci/oci_api_key.pem"                       # Path to your private key for OCI API access
region           = "us-sanjose-1"                                          # Target OCI region

# --- Compartment, Network, and Availability Domain ---
compartment_ocid = "ocid1.compartment.oc1..xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" # Target compartment OCID for resources
vcn_id           = "ocid1.vcn.oc1..xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"         # OCID of your VCN
subnet_id        = "ocid1.subnet.oc1..xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"      # OCID of your subnet
ad_number        = 1                                                       # Availability Domain number (1, 2, or 3)

# --- Project Tagging & Meta ---
project_name = "myproject" # Name prefix for all resources
tags         = {}          # Optional map of tags (e.g. {"Environment" = "dev"})

# --- SSH Keys and Connectivity ---
ssh_public_key   = "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQ..." # SSH public key for all instance access
ssh_keys_dir     = "./ssh"                                     # Path to store SSH keys generated or used
assign_public_ip = true                                        # Assign public IPs to compute instances
fault_domain     = ""                                          # (Optional) Fault domain name, or leave empty for auto

# --- Component Enablement ---
deploy_components = ["all"] # Which components to deploy. Options: ["clients", "storage", "hammerspace", "ecgroup", "ansible", "all"]

##############################################################################
# Images & Shapes - Use correct OCIDs and shapes for your region/tenancy     #
##############################################################################

# --- Compute Image OCIDs ---
clients_image_id     = "ocid1.image.oc1..xxxxxxx"                     # OCI image OCID for client nodes
storage_image_id     = "ocid1.image.oc1..yyyyyyy"                     # OCI image OCID for storage nodes
hammerspace_image_id = "ocid1.image.oc1..zzzzzzz"                     # OCI image OCID for Hammerspace nodes
ansible_image_id     = "ocid1.image.oc1..aaaaaaa"                     # OCI image OCID for Ansible node
ecgroup_image_id     = "ocid1.image.oc1..specific_ecgroup_image_ocid" # OCI image OCID for ECGroup nodes

# --- Compute Shapes ---
clients_instance_shape           = "VM.Standard.E4.Flex" # Shape for client instances
storage_instance_shape           = "VM.Standard.E4.Flex" # Shape for storage instances
hammerspace_anvil_instance_shape = "VM.Standard.E4.Flex" # Shape for Hammerspace Anvil nodes
hammerspace_dsx_instance_shape   = "VM.Standard.E4.Flex" # Shape for Hammerspace DSX nodes
ecgroup_instance_shape           = "VM.Standard.E4.Flex" # Shape for ECGroup nodes
ansible_instance_shape           = "VM.Standard.E4.Flex" # Shape for Ansible node

# --- OCPU and Memory Configuration for Flex Shapes ---
clients_ocpus                = 8   # Number of OCPUs for client instances
clients_memory_gbs           = 128 # Memory in GB for client instances
storage_ocpus                = 8   # Number of OCPUs for storage instances
storage_memory_gbs           = 128 # Memory in GB for storage instances
hammerspace_anvil_ocpus      = 12  # Number of OCPUs for Anvil instances
hammerspace_anvil_memory_gbs = 192 # Memory in GB for Anvil instances
hammerspace_dsx_ocpus        = 2   # Number of OCPUs for DSX instances
hammerspace_dsx_memory_gbs   = 32  # Memory in GB for DSX instances
ecgroup_ocpus                = 16  # Number of OCPUs for ECGroup instances
ecgroup_memory_gbs           = 256 # Memory in GB for ECGroup instances
ansible_ocpus                = 8   # Number of OCPUs for Ansible instances
ansible_memory_gbs           = 128 # Memory in GB for Ansible instances

##############################################################################
# Instance Counts                                                            #
##############################################################################
clients_instance_count  = 2 # Number of client instances to deploy
storage_instance_count  = 2 # Number of storage instances to deploy
hammerspace_anvil_count = 1 # Number of Hammerspace Anvil nodes
hammerspace_dsx_count   = 1 # Number of Hammerspace DSX nodes
ecgroup_node_count      = 0 # Number of ECGroup nodes (set > 0 to enable)
ansible_instance_count  = 1 # Number of Ansible nodes

##############################################################################
# Block/Boot Volume Configuration                                            #
##############################################################################

# --- Clients ---
clients_boot_volume_size        = 50                # GB
clients_boot_volume_type        = "paravirtualized" # Options: "paravirtualized", "iscsi"
clients_block_volume_count      = 2
clients_block_volume_size       = 100 # GB
clients_block_volume_type       = "paravirtualized"
clients_block_volume_throughput = 0 # MB/s (0 = use default)
clients_block_volume_iops       = 0 # IOPS (0 = use default)

# --- Storage Servers ---
storage_boot_volume_size        = 100
storage_boot_volume_type        = "paravirtualized"
storage_block_volume_count      = 2
storage_raid_level              = "raid-0" # RAID level: raid-0, raid-5, or raid-6
storage_block_volume_size       = 200
storage_block_volume_type       = "paravirtualized"
storage_block_volume_throughput = 0 # MB/s (0 = use default)
storage_block_volume_iops       = 0 # IOPS (0 = use default)

# --- Hammerspace ---
hammerspace_profile_id                  = ""    # Profile or role ID if needed by your module
hammerspace_anvil_security_group_id     = ""    # Security group for Anvil, if used
hammerspace_dsx_security_group_id       = ""    # Security group for DSX, if used
hammerspace_sa_anvil_destruction        = false # Enable/disable Anvil self-destruct
hammerspace_anvil_meta_disk_size        = 100   # GB
hammerspace_anvil_meta_disk_type        = "paravirtualized"
hammerspace_anvil_meta_disk_iops        = 0   # IOPS (0 = use default)
hammerspace_anvil_meta_disk_throughput  = 0   # MB/s (0 = use default)
hammerspace_dsx_block_volume_size       = 100 # GB
hammerspace_dsx_block_volume_type       = "paravirtualized"
hammerspace_dsx_block_volume_iops       = 0 # IOPS (0 = use default)
hammerspace_dsx_block_volume_throughput = 0 # MB/s (0 = use default)
hammerspace_dsx_block_volume_count      = 1
hammerspace_dsx_add_vols                = true # Create additional DSX data volumes

# --- ECGroup ---
ecgroup_boot_volume_size           = 100 # GB
ecgroup_boot_volume_type           = "paravirtualized"
ecgroup_metadata_volume_type       = "paravirtualized"
ecgroup_metadata_volume_size       = 50 # GB
ecgroup_metadata_volume_throughput = 0  # MB/s (0 = use default)
ecgroup_metadata_volume_iops       = 0  # IOPS (0 = use default)
ecgroup_storage_volume_count       = 0  # Number of storage volumes per node
ecgroup_storage_volume_type        = "paravirtualized"
ecgroup_storage_volume_size        = 0 # GB
ecgroup_storage_volume_throughput  = 0 # MB/s (0 = use default)
ecgroup_storage_volume_iops        = 0 # IOPS (0 = use default)

# --- Ansible ---
ansible_boot_volume_size = 100
ansible_boot_volume_type = "paravirtualized"

##############################################################################
# User Data & OS User Settings                                               #
##############################################################################

# For advanced cloud-init/user_data, provide here or leave blank for default
clients_user_data   = ""
clients_target_user = "opc"
storage_user_data   = ""
storage_target_user = "opc"
ecgroup_user_data   = ""
ansible_user_data   = ""
ansible_target_user = "opc"

##############################################################################
# Ansible & Storage Specifics                                                #
##############################################################################
volume_group_name = "vg-auto" # Volume group name for LVM or other storage group
share_name        = ""        # Share name for NFS/SMB etc.

